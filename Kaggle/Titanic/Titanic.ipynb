{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "TITANIC_PATH = os.path.join(\"datasets\", \"titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_titanic_data(filename, titanic_path=TITANIC_PATH):\n",
    "    csv_path = os.path.join(titanic_path, filename)\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_titanic_data(\"train.csv\")\n",
    "test_data = load_titanic_data(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Survived'].notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_full = train_data['Survived'] \n",
    "y_train_full=y_train_full.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop('Survived', inplace=True, axis=1)\n",
    "train_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(train_data['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making class manually\n",
    "def numericalLabelling(status):\n",
    "    status = str(status)\n",
    "    if status in ['Capt','Col','Major','Dr','Rev']:\n",
    "        return 0\n",
    "    elif status in ['Don','Jonkheer','Master', 'Sir']:\n",
    "        return 1\n",
    "    elif status in ['Mr']:\n",
    "        return 2\n",
    "    elif status in ['Miss', 'Mlle', 'Mrs', 'Ms']:\n",
    "        return 3\n",
    "    elif status in ['Lady','Mme', 'Dona','Countess']:\n",
    "        return 4\n",
    "\n",
    "train_data['Status']=train_data['Name'].str.extract(' ([A-Za-z]+)\\.', expand = False)\n",
    "train_data['Status']=train_data['Status'].apply(numericalLabelling)\n",
    "set(train_data['Status'])\n",
    "\n",
    "test_data['Status']=test_data['Name'].str.extract(' ([A-Za-z]+)\\.', expand = False)\n",
    "test_data['Status']=test_data['Status'].apply(numericalLabelling)\n",
    "set(test_data['Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_data, y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "\n",
    "\n",
    "data = X_train[[\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Embarked\",\"Status\"]] #useful keys\n",
    "data.Sex= ((data.Sex == \"female\" )*1) #convert to numerical\n",
    "\n",
    "data.Age = data.Age.fillna(data.Age.median())\n",
    "le.fit(data[\"Embarked\"])\n",
    "data[\"Embarked\"]=le.transform(data[\"Embarked\"])\n",
    "\n",
    "X_train=data.to_numpy()\n",
    "scaler.fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X_valid[[\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Embarked\",\"Status\"]] \n",
    "data.Sex= ((data.Sex == \"female\" )*1) #convert to numerical\n",
    "\n",
    "data.Age = data.Age.fillna(data.Age.median())\n",
    "data[\"Embarked\"]=le.transform(data[\"Embarked\"])\n",
    "X_valid=data.to_numpy()\n",
    "X_valid=scaler.transform(X_valid)\n",
    "X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = test_data[[\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Embarked\",\"Status\"]] \n",
    "data_test.Sex= ((data_test.Sex == \"female\" )*1) #convert to numerical\n",
    "\n",
    "data_test.Age = data_test.Age.fillna(data_test.Age.median())\n",
    "data_test.Fare = data_test.Fare.fillna(data_test.Fare.median())\n",
    "data_test[\"Embarked\"]=le.transform(data_test[\"Embarked\"])\n",
    "X_test=data_test.to_numpy()\n",
    "X_test=scaler.transform(X_test)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_NaN = data_test.isnull()\n",
    "row_has_NaN = is_NaN.any(axis=1)\n",
    "rows_with_NaN = data_test[row_has_NaN]\n",
    "\n",
    "\n",
    "print(rows_with_NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.callbacks import History\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "print(tf.__version__)\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "    initial_lrate = 0.01#dodac 0 #dodac 0\n",
    "    drop = 0.9#defult 0.5\n",
    "    epochs_drop = 8.0\n",
    "    lrate = initial_lrate * np.power(drop, np.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard \n",
    "\n",
    "tensorboard_cb = TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.keras.initializers.HeNormal(seed=None)\n",
    "history = History()\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(100, kernel_initializer=initializer,use_bias=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"elu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, kernel_initializer=initializer,use_bias=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"elu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(20, kernel_initializer=initializer,use_bias=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"elu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "#round(model.optimizer.lr.numpy(), 5)\n",
    "callback = [tf.keras.callbacks.LearningRateScheduler(scheduler),\n",
    "history,\n",
    "tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, mode='min'),\n",
    "tensorboard_cb]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, validation_data= (X_valid, y_valid), batch_size=32,epochs=500,callbacks=callback)\n",
    "\n",
    "model.save('LastModel')\n",
    "\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=.my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import  metrics\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "metrics.accuracy_score(y_true= y_valid, y_pred= model.predict_classes(X_valid) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "predictions =model.predict(X_test)\n",
    "print(np.shape(predictions))\n",
    "print()\n",
    "print(predictions.round(0).astype(int).reshape(-1))\n",
    "\n",
    "df=pd.DataFrame(predictions.round(0).astype(int).reshape(-1), columns=['Survived'])['Survived']\n",
    "\n",
    "df2 = pd.concat([data_test['PassengerId'], df], axis=1, join=\"inner\")\n",
    "print(df2)\n",
    "#plt.show(predictions.round(0).astype(int).reshape(-1))\n",
    "prediction = df2.to_csv('prediction.csv',index=False)#"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8420e14ffc0620a853927d0d4feb4e90de91bae3b0a41c2b35fe66c147e210b9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
